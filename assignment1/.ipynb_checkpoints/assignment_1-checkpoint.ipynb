{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a55655cba14c313eed90e50c1cdba913",
     "grade": false,
     "grade_id": "cell-d8b377aba23d9f3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Mandatory Assignment 1\n",
    "\n",
    "This is the second of three mandatory assignments which must be completed during the course. Note that you only need to pass 2 out of 3 assignments to be eligible for the exam.\n",
    "\n",
    "First some practical pieces of information:\n",
    "\n",
    "* When is the assignment due?: **23:59, Friday, August 5, 2022.**\n",
    "* Should i work with my group?: **Yes**. In particular, you should **only hand in 1 assignment per group and in a comment on Absalon write your group number and all group members**. \n",
    "\n",
    "The assignment consists of problems from the exercise sets that you have solved so far, problems from the exercises that have been modified a little to better suit the structure of the assignment and finally also new problems not seen in the exercises. \n",
    "\n",
    "**Note**: \n",
    "- It is important that you submit your edited version of this [notebook](https://fileinfo.com/extension/ipynb#:~:text=An%20IPYNB%20file%20is%20a,Python%20language%20and%20their%20data.) as a .ipynb file and nothing else. Do not copy your answers into another notebook that you have made. \n",
    "- Don't delete the empty non-editable (unless you specifically change the metadata) cells below each question. Those are hidden tests used by the `nbgrader` software to grade the assignment.\n",
    "- It is recommended to clone our [github repository](https://github.com/isdsucph/isds2022) and copy the entire `assignment1` folder to somewhere on your computer and complete the assignment in this folder.\n",
    "- It is good practice to always restart your notebook and run all cells before submitting or delivering your notebook to somebody else. This is to make sure that all cells run without raising any errors breaking the flow of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "459a25bfbfe70234fb99397dd7a844c4",
     "grade": false,
     "grade_id": "cell-e5576badd2b58d90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 2:\n",
    "\n",
    "This time we are going to **read the weather data from a csv file** located in this assignment directory instead of requesting the website.\n",
    "The file is called `weather_data_1870-1875.csv` and consists of weather data for the period 1870-1875. The csv file contains data which has been constructed by concatenating the _non-processed_ data from 1870-1875. In a later exercise we will need metadata about the stations so the weather data comes bundled inside a zip file called `data.zip` together with the metadata files. \n",
    "\n",
    "First, we want to create a folder to extract the data inside the zip file to. We'll use the [`Path`](https://docs.python.org/3/library/pathlib.html#pathlib.Path) object from the [`pathlib`](https://docs.python.org/3/library/pathlib.html) module to create our data folder. With the `Path` object we can construct new file paths by using the `/` operator. For instance, to create a new folder called `some_dir` located inside the directory containing this notebook we can write \n",
    "\n",
    "```python\n",
    "## Code snippet showing how to use the `/` operator\n",
    "# Create Path object of new folder located inside \n",
    "# the current working directory of this notebook\n",
    "fp = Path.cwd() / \"some_dir\"  \n",
    "# Use the Path object to actually create the subfolder\n",
    "Path.mkdir(fp, exist_ok=True)  \n",
    "```\n",
    "It is good practice to construct paths relative to the project directory. With `pathlib` this becomes easy, also across operating systems. If you are interested you can read more about the `pathlib` module [here](https://realpython.com/python-pathlib/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.X.1 (Not seen in module 2):**\n",
    "Use the code snippet above to create a subfolder located inside this directory named `data`. Store the path as a `Path` object inside the variable `fp_data`. We will use `fp_data` in the next exercise when extracting the zipfile's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15def5ae0510f32dca69b04ddc50b1ec",
     "grade": false,
     "grade_id": "2x1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Code snippet showing how to use the `/` operator\n",
    "# Create Path object of new folder located inside \n",
    "# the current working directory of this notebook\n",
    "fp_data = Path.cwd() / \"data\"  \n",
    "# Use the Path object to actually create the subfolder\n",
    "Path.mkdir(fp_data, exist_ok=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bae59332888da39f84684680cc31fcde",
     "grade": true,
     "grade_id": "2x1-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ab3bf517ced19d3f422f2f65d15d918",
     "grade": false,
     "grade_id": "cell-4ae37c71df382dbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.X.2 (Not seen in module 2):** Use the [`zipfile`](https://docs.python.org/3/library/zipfile.html) module to extract the content of `data.zip` to the subfolder created above. \n",
    "\n",
    "> _Hint:_ Use the [`extractall`](https://docs.python.org/3/library/zipfile.html#zipfile.ZipFile.extractall) method of the `ZipFile` object. See [here](https://thispointer.com/python-how-to-unzip-a-file-extract-single-multiple-or-all-files-from-a-zip-archive/) for a guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "028470c2eda880b8d38bfe16a40b71a2",
     "grade": false,
     "grade_id": "2x2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ghcnd-stations.txt',\n",
       " 'ghcnd-stations-column-metadata.txt',\n",
       " 'weather_data_1870-1875.csv']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with ZipFile('data.zip', 'r') as zipObj:\n",
    "   # Get a list of all archived file names from the zip\n",
    "   listOfFileNames = zipObj.namelist()\n",
    "listOfFileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('data.zip', 'r') as zipObj:\n",
    "    zipObj.extractall(path=fp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c746efc3c12830df77e2f92b375f4d61",
     "grade": true,
     "grade_id": "2x2-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d5325888798d10692c986771969c91c",
     "grade": false,
     "grade_id": "cell-3949fc8a0311b795",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.3.4:** The code below runs through some of the steps we completed in exercise 2.3.4 in Module 2. As we are not going to request the website but load the data from a csv file, your task is to **rewrite parts of the function**. In particular, you need to do the following:`\n",
    ">1. Rename the function to `process_weather` instead of `load_weather`. \n",
    ">2. The function should now  take a `DataFrame` as input (the one we extracted from the zip file)\n",
    ">3. Consider whether `df_weather.iloc[:, :4]` is necessary for the weather data loaded from  the csv file. The documentation string should also be rewritten appropriately. \n",
    ">4. The function contains a sorting step. **Change it so that it first sorts by _station_, then by _datetime_. The sorting should be ascending for _station_ and descending for _datetime_.** \n",
    ">5. After having rewritten the function, load the weather data from `'weather_data_1870-1875.csv'` into a pandas dataframe, apply the `process_weather` function to this dataframe, and store the result in the variable `df_weather_period`.\n",
    "\n",
    "```python\n",
    "def load_weather(year):\n",
    "    \"\"\"Function to structure and clean weather data.\n",
    "    \n",
    "    Structuring includes removing unused columns, renaming the \n",
    "    columns and selecting only observations of maximum temperature. \n",
    "    Cleaning includes inserting missing decimal, sorting and\n",
    "    resetting the index.\n",
    "    \n",
    "    Args:\n",
    "        year (int): given year to load data from e.g. 1870\n",
    "        \n",
    "    Returns:\n",
    "        (pd.DataFrame): processed weather data for given input year\n",
    "    \"\"\"\n",
    "    url = f\"ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/{year}.csv.gz\"\n",
    "\n",
    "    # loads the data\n",
    "    df_weather = pd.read_csv(url, header=None)\\\n",
    "                    .iloc[:,:4] \n",
    "\n",
    "    # structure and clean data using methods chaining\n",
    "    # note that the original columns now are strings when loading the csv file\n",
    "    # and not integers as when downloading the data\n",
    "    df_out = \\\n",
    "        df_weather\\\n",
    "            .rename(columns={'0': 'station', '1': 'datetime', '2': 'obs_type', '3': 'obs_value'})\\\n",
    "            .query(\"obs_type == 'TMAX'\")\\\n",
    "            .assign(obs_value=lambda df: df['obs_value']/10)\\\n",
    "            .sort_values(by=['station', 'datetime'])\\\n",
    "            .reset_index(drop=True)\\\n",
    "            .copy() \n",
    "\n",
    "    # area process\n",
    "    df_out['area'] = df_out['station'].str[0:2]\n",
    "\n",
    "    # datetime process\n",
    "    df_out['datetime_dt'] = pd.to_datetime(df_out['datetime'], format = '%Y%m%d')\n",
    "    df_out['month'] = df_out['datetime_dt'].dt.month\n",
    "    df_out['year'] = df_out['datetime_dt'].dt.year\n",
    "\n",
    "    return df_out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0fcfb2b712a697a2c519e6f2d4102b6",
     "grade": false,
     "grade_id": "problem_234",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def process_weather(df):\n",
    "    \"\"\"Function to structure and clean weather data.\n",
    "    \n",
    "    Structuring includes removing unused columns, renaming the \n",
    "    columns and selecting only observations of maximum temperature. \n",
    "    Cleaning includes inserting missing decimal, sorting and\n",
    "    resetting the index.\n",
    "    \n",
    "    Args:\n",
    "        pd.DataFrame: raw weather data with 4 columns, named [0,1,2,3]\n",
    "        \n",
    "    Returns:\n",
    "        (pd.DataFrame): processed weather data for given input year\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # structure and clean data using methods chaining\n",
    "    # note that the original columns now are strings when loading the csv file\n",
    "    # and not integers as when downloading the data\n",
    "    df_out = \\\n",
    "        df\\\n",
    "            .rename(columns={'0': 'station', '1': 'datetime', '2': 'obs_type', '3': 'obs_value'})\\\n",
    "            .query(\"obs_type == 'TMAX'\")\\\n",
    "            .assign(obs_value=lambda df: df['obs_value']/10)\\\n",
    "            .sort_values(by=['station', 'datetime'], ascending = [True, False])\\\n",
    "            .reset_index(drop=True)\\\n",
    "            .copy() \n",
    "\n",
    "    # area process\n",
    "    df_out['area'] = df_out['station'].str[0:2]\n",
    "\n",
    "    # datetime process\n",
    "    df_out['datetime_dt'] = pd.to_datetime(df_out['datetime'], format = '%Y%m%d')\n",
    "    df_out['month'] = df_out['datetime_dt'].dt.month\n",
    "    df_out['year'] = df_out['datetime_dt'].dt.year\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(\"data/weather_data_1870-1875.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_period = process_weather(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>datetime</th>\n",
       "      <th>obs_type</th>\n",
       "      <th>obs_value</th>\n",
       "      <th>area</th>\n",
       "      <th>datetime_dt</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751117</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>38.3</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-17</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751116</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>33.8</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-16</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751115</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>32.8</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-15</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751114</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>35.6</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-14</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751113</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>29.7</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-13</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132312</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700105</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>1.1</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132313</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700104</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>1.7</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132314</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700103</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132315</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700102</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>12.2</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132316</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>6.1</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132317 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            station  datetime obs_type  obs_value area datetime_dt  month  \\\n",
       "0       ASN00048013  18751117     TMAX       38.3   AS  1875-11-17     11   \n",
       "1       ASN00048013  18751116     TMAX       33.8   AS  1875-11-16     11   \n",
       "2       ASN00048013  18751115     TMAX       32.8   AS  1875-11-15     11   \n",
       "3       ASN00048013  18751114     TMAX       35.6   AS  1875-11-14     11   \n",
       "4       ASN00048013  18751113     TMAX       29.7   AS  1875-11-13     11   \n",
       "...             ...       ...      ...        ...  ...         ...    ...   \n",
       "132312  USW00094728  18700105     TMAX        1.1   US  1870-01-05      1   \n",
       "132313  USW00094728  18700104     TMAX        1.7   US  1870-01-04      1   \n",
       "132314  USW00094728  18700103     TMAX        5.0   US  1870-01-03      1   \n",
       "132315  USW00094728  18700102     TMAX       12.2   US  1870-01-02      1   \n",
       "132316  USW00094728  18700101     TMAX        6.1   US  1870-01-01      1   \n",
       "\n",
       "        year  \n",
       "0       1875  \n",
       "1       1875  \n",
       "2       1875  \n",
       "3       1875  \n",
       "4       1875  \n",
       "...      ...  \n",
       "132312  1870  \n",
       "132313  1870  \n",
       "132314  1870  \n",
       "132315  1870  \n",
       "132316  1870  \n",
       "\n",
       "[132317 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7189d84de812b64c7424088e3ca325b",
     "grade": true,
     "grade_id": "problem_234_tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78e78d64830c5518e7ef3173d94bf33c",
     "grade": false,
     "grade_id": "cell-7a8591d457df256a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.X.3 (Not seen in module 2):** Try to plot the observations value of `df_weather_period` by running `df_weather_period.obs_value.plot()`. Something seems off, right? Now try to inspect the problematic subset of the dataframe by running `df_weather_period[df_weather_period.obs_value < -50]`. What can these three observations be characterized as? Drop _all_ observations from the associated station from `df_weather_period`, reset the index and drop the column with the old index. Store the dataframe back into the variable `df_weather_period`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2de59076e97751d5e76fa532723f768",
     "grade": false,
     "grade_id": "problem_notseenexercises",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_weather_period.obs_value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>datetime</th>\n",
       "      <th>obs_type</th>\n",
       "      <th>obs_value</th>\n",
       "      <th>area</th>\n",
       "      <th>datetime_dt</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126366</th>\n",
       "      <td>USW00023068</td>\n",
       "      <td>18751115</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-573.3</td>\n",
       "      <td>US</td>\n",
       "      <td>1875-11-15</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126397</th>\n",
       "      <td>USW00023068</td>\n",
       "      <td>18751015</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-573.3</td>\n",
       "      <td>US</td>\n",
       "      <td>1875-10-15</td>\n",
       "      <td>10</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126398</th>\n",
       "      <td>USW00023068</td>\n",
       "      <td>18751014</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-573.3</td>\n",
       "      <td>US</td>\n",
       "      <td>1875-10-14</td>\n",
       "      <td>10</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            station  datetime obs_type  obs_value area datetime_dt  month  \\\n",
       "126366  USW00023068  18751115     TMAX     -573.3   US  1875-11-15     11   \n",
       "126397  USW00023068  18751015     TMAX     -573.3   US  1875-10-15     10   \n",
       "126398  USW00023068  18751014     TMAX     -573.3   US  1875-10-14     10   \n",
       "\n",
       "        year  \n",
       "126366  1875  \n",
       "126397  1875  \n",
       "126398  1875  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_period[df_weather_period.obs_value < -50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>datetime</th>\n",
       "      <th>obs_type</th>\n",
       "      <th>obs_value</th>\n",
       "      <th>area</th>\n",
       "      <th>datetime_dt</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751117</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>38.3</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-17</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751116</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>33.8</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-16</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751115</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>32.8</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-15</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751114</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>35.6</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-14</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751113</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>29.7</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-13</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132312</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700105</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>1.1</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132313</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700104</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>1.7</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132314</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700103</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132315</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700102</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>12.2</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132316</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>6.1</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131820 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            station  datetime obs_type  obs_value area datetime_dt  month  \\\n",
       "0       ASN00048013  18751117     TMAX       38.3   AS  1875-11-17     11   \n",
       "1       ASN00048013  18751116     TMAX       33.8   AS  1875-11-16     11   \n",
       "2       ASN00048013  18751115     TMAX       32.8   AS  1875-11-15     11   \n",
       "3       ASN00048013  18751114     TMAX       35.6   AS  1875-11-14     11   \n",
       "4       ASN00048013  18751113     TMAX       29.7   AS  1875-11-13     11   \n",
       "...             ...       ...      ...        ...  ...         ...    ...   \n",
       "132312  USW00094728  18700105     TMAX        1.1   US  1870-01-05      1   \n",
       "132313  USW00094728  18700104     TMAX        1.7   US  1870-01-04      1   \n",
       "132314  USW00094728  18700103     TMAX        5.0   US  1870-01-03      1   \n",
       "132315  USW00094728  18700102     TMAX       12.2   US  1870-01-02      1   \n",
       "132316  USW00094728  18700101     TMAX        6.1   US  1870-01-01      1   \n",
       "\n",
       "        year  \n",
       "0       1875  \n",
       "1       1875  \n",
       "2       1875  \n",
       "3       1875  \n",
       "4       1875  \n",
       "...      ...  \n",
       "132312  1870  \n",
       "132313  1870  \n",
       "132314  1870  \n",
       "132315  1870  \n",
       "132316  1870  \n",
       "\n",
       "[131820 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_period[df_weather_period.station != \"USW00023068\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_weather_period) - len(df_weather_period[df_weather_period.station != \"USW00023068\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_weather_period[df_weather_period.station == \"USW00023068\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_period = df_weather_period[df_weather_period.station != \"USW00023068\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_period.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5971a3b2c04c14fb5fb5f180e25ff481",
     "grade": true,
     "grade_id": "problem_notseenexercises_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1b79752e5634da4d89aa3ae634563e0",
     "grade": false,
     "grade_id": "cell-c2f8ff075ab551a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 2.3.2:** \n",
    "Continuing with the `df_weather_period` from last exercise, do the following:\n",
    "> 1. Convert the `area` column to a categorical variable. \n",
    "> 2. Transform the `obs_value` column from a continuous to a categorical variable by partitioning it into `3` intervals. The first interval should contain observations with values of `obs_value` up to the 10% quantile. The second interval should contain observations with values of `obs_value` up to the 90% quantile. The third interval should contain the rest of the observations. Call this new column for `obs_value_cat`.  This can be done using the `pd.qcut()` method.\n",
    "> 3. Make another column with  `obs_value` as a categorical variable but this time label the 3 intervals as `[\"cold\", \"medium\", \"hot\"]`. This can be done by specifying the `labels` parameter in the `pd.qcut()` method of pandas. Call this new column for `obs_value_cat_labeled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a0243b6c65b39af72e8d1efead106e8",
     "grade": false,
     "grade_id": "problem_232",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         AS\n",
       "1         AS\n",
       "2         AS\n",
       "3         AS\n",
       "4         AS\n",
       "          ..\n",
       "131815    US\n",
       "131816    US\n",
       "131817    US\n",
       "131818    US\n",
       "131819    US\n",
       "Name: area, Length: 131820, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_period[\"area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MZB\\AppData\\Local\\Temp/ipykernel_9116/3150032819.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_weather_period[\"area\"] = pd.Categorical(df_weather_period.area)\n"
     ]
    }
   ],
   "source": [
    "df_weather_period[\"area\"] = pd.Categorical(df_weather_period.area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MZB\\AppData\\Local\\Temp/ipykernel_9116/3146600214.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_weather_period[\"obs_value_cat\"] = pd.qcut(df_weather_period[\"obs_value\"], q = [0, 0.1, 0.9, 1] )\n"
     ]
    }
   ],
   "source": [
    "df_weather_period[\"obs_value_cat\"] = pd.qcut(df_weather_period[\"obs_value\"], q = [0, 0.1, 0.9, 1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MZB\\AppData\\Local\\Temp/ipykernel_9116/3427137358.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_weather_period[\"obs_value_cat_labeled\"] = pd.qcut(df_weather_period[\"obs_value\"], q = [0, 0.1, 0.9, 1] , labels = [\"cold\", \"medium\", \"hot\"])\n"
     ]
    }
   ],
   "source": [
    "df_weather_period[\"obs_value_cat_labeled\"] = pd.qcut(df_weather_period[\"obs_value\"], q = [0, 0.1, 0.9, 1] , labels = [\"cold\", \"medium\", \"hot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>datetime</th>\n",
       "      <th>obs_type</th>\n",
       "      <th>obs_value</th>\n",
       "      <th>area</th>\n",
       "      <th>datetime_dt</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>obs_value_cat</th>\n",
       "      <th>obs_value_cat_labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751117</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>38.3</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-17</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "      <td>(28.3, 47.8]</td>\n",
       "      <td>hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751116</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>33.8</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-16</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "      <td>(28.3, 47.8]</td>\n",
       "      <td>hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751115</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>32.8</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-15</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "      <td>(28.3, 47.8]</td>\n",
       "      <td>hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751114</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>35.6</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-14</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "      <td>(28.3, 47.8]</td>\n",
       "      <td>hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASN00048013</td>\n",
       "      <td>18751113</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>29.7</td>\n",
       "      <td>AS</td>\n",
       "      <td>1875-11-13</td>\n",
       "      <td>11</td>\n",
       "      <td>1875</td>\n",
       "      <td>(28.3, 47.8]</td>\n",
       "      <td>hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131815</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700105</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>1.1</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "      <td>(-1.1, 28.3]</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131816</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700104</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>1.7</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "      <td>(-1.1, 28.3]</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131817</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700103</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "      <td>(-1.1, 28.3]</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131818</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700102</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>12.2</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "      <td>(-1.1, 28.3]</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131819</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>18700101</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>6.1</td>\n",
       "      <td>US</td>\n",
       "      <td>1870-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1870</td>\n",
       "      <td>(-1.1, 28.3]</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131820 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            station  datetime obs_type  obs_value area datetime_dt  month  \\\n",
       "0       ASN00048013  18751117     TMAX       38.3   AS  1875-11-17     11   \n",
       "1       ASN00048013  18751116     TMAX       33.8   AS  1875-11-16     11   \n",
       "2       ASN00048013  18751115     TMAX       32.8   AS  1875-11-15     11   \n",
       "3       ASN00048013  18751114     TMAX       35.6   AS  1875-11-14     11   \n",
       "4       ASN00048013  18751113     TMAX       29.7   AS  1875-11-13     11   \n",
       "...             ...       ...      ...        ...  ...         ...    ...   \n",
       "131815  USW00094728  18700105     TMAX        1.1   US  1870-01-05      1   \n",
       "131816  USW00094728  18700104     TMAX        1.7   US  1870-01-04      1   \n",
       "131817  USW00094728  18700103     TMAX        5.0   US  1870-01-03      1   \n",
       "131818  USW00094728  18700102     TMAX       12.2   US  1870-01-02      1   \n",
       "131819  USW00094728  18700101     TMAX        6.1   US  1870-01-01      1   \n",
       "\n",
       "        year obs_value_cat obs_value_cat_labeled  \n",
       "0       1875  (28.3, 47.8]                   hot  \n",
       "1       1875  (28.3, 47.8]                   hot  \n",
       "2       1875  (28.3, 47.8]                   hot  \n",
       "3       1875  (28.3, 47.8]                   hot  \n",
       "4       1875  (28.3, 47.8]                   hot  \n",
       "...      ...           ...                   ...  \n",
       "131815  1870  (-1.1, 28.3]                medium  \n",
       "131816  1870  (-1.1, 28.3]                medium  \n",
       "131817  1870  (-1.1, 28.3]                medium  \n",
       "131818  1870  (-1.1, 28.3]                medium  \n",
       "131819  1870  (-1.1, 28.3]                medium  \n",
       "\n",
       "[131820 rows x 10 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ea686468a1612c1453d6013671443b9",
     "grade": true,
     "grade_id": "problem_232_tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0e767d450ff726563ebe1bdb729215f",
     "grade": false,
     "grade_id": "cell-77eabac0ab0cbce5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f6944ea47bde40b92ba269f19d16439",
     "grade": false,
     "grade_id": "cell-4975a2e1ab215936",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.1:** Compute the mean and median maximum daily temperature for each month-year-station pair on the dataframe `df_weather_period` from last exercise by using the _split-apply-combine_ procedure. Store the results in new columns `tmax_mean` and `tmax_median`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce92e895d0a63283094fe6c661cb5b66",
     "grade": false,
     "grade_id": "problem_331",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b200933c81339b97661155bc29d76cef",
     "grade": true,
     "grade_id": "problem_331_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e4d376c6fe462ddc61d2839b982968b",
     "grade": false,
     "grade_id": "cell-7e77713f98953bac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.2:** Plot the monthly max,min, mean, first and third quartiles for maximum temperature for the station with ID _'CA006110549'_ from `df_weather_period`.\n",
    "\n",
    "> *Hint*: the method `describe` computes all these measures. Try to make your plot look like the one below. \n",
    "\n",
    "<img src=\"station_data_plot.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca1afdbf1edee8beacbfc1e95d6ac2e4",
     "grade": true,
     "grade_id": "problem_332_tests",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf7d78380538170cdb3f8da6d976c6cd",
     "grade": false,
     "grade_id": "cell-539af69a1ea23069",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3: (MODIFIED FOR ASSIGNMENT 1)** We want to use the location data of the weather stations and merge this onto `df_weather_period`. The file with station location data is called  `ghcnd-stations.txt` and is stored in the `data.zip` file. Therefore, by Ex. 2.X.2, it should now be located in the `data` folder of this directory. `pandas` has a function named [`read_fwf`](https://pandas.pydata.org/docs/reference/api/pandas.read_fwf.html) which can be used to read a txt file with a fixed width format (each variable spans a fixed amount of columns). The function is neat and can infer how many columns each variable spans automatically (if the `infer_nrows` parameter is set properly). One can also manually set the `colspecs` parameter equal to a list of tuples containing the fixed-width intervals that the variables span. In the following exercise we will use some extra time and do the job manually to practice our txt file and string skills. Specifically, we will extract the list of tuples with fixed-widht information together with the column names and datatypes from the `ghcnd-stations-column-metadata.txt` file (also included in the `data.zip` file). \n",
    "\n",
    "> The `ghcnd-stations-column-metadata.txt` file looks like this: \n",
    "\n",
    "```\n",
    "------------------------------\n",
    "Variable   Columns   Type\n",
    "------------------------------\n",
    "ID            1-11   Character\n",
    "LATITUDE     13-20   Real\n",
    "LONGITUDE    22-30   Real\n",
    "ELEVATION    32-37   Real\n",
    "STATE        39-40   Character\n",
    "NAME         42-71   Character\n",
    "GSN FLAG     73-75   Character\n",
    "HCN/CRN FLAG 77-79   Character\n",
    "WMO ID       81-85   Character\n",
    "------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4d926a239ad69a32e6ddcb443ef42a0",
     "grade": false,
     "grade_id": "cell-6a3113e42875692a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.1:** Read the `ghcnd-stations-column-metadata.txt` using the `with` keyword, see [here](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files), and store it in a variable called `column_metadata`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be143fcf053d269b2048157e33dc225c",
     "grade": false,
     "grade_id": "3331",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1406fd53b4dd29083588279108f8b861",
     "grade": true,
     "grade_id": "3331-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d348ada2f5d006ebbb11b024f7139bc",
     "grade": false,
     "grade_id": "cell-9c66cca32bfbef31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.2:** Split `column_metadata` into a list of strings by applying the method `split` with the proper argument. Subset the resulting list and extract all lines from index `3` to `12` (non-inclusive) of the variable. Store the final list in a variable named `lines`. Inspect the result to make sure the relevant rows of the txt file has been extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6850caaabe8ccf9c93f8449beda38043",
     "grade": false,
     "grade_id": "3332",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a01223ced1b81abc7bb54537a1923fd3",
     "grade": true,
     "grade_id": "3332-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a2d97eb10f8245bcb67a28a98be2d91",
     "grade": false,
     "grade_id": "cell-6d6084e723953822",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.3:** Inspecting each line of the `lines` variable we see that the information about the column widths are all located from index `13` up and including index `17`. Finish the `get_colspecs` function below to extract the fixed width information from the `lines` variable by completing the steps below:\n",
    "1. Use a list comprehension to loop through each line of the file\n",
    "2. Index each line by the relevant indices written above\n",
    "3. Strip leading whitespace of each element (if necessary)\n",
    "\n",
    "> Finally, apply `get_colspecs` to the `lines` variable and store the result in a new variable called `colspecs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca2823ed345d0dd66e8782cd4da05ea2",
     "grade": false,
     "grade_id": "3333",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_colspecs(lines):\n",
    "    \"\"\"Extracts colspecs from `ghcnd-stations-column-metadata.txt`.\n",
    "    \n",
    "    Args:\n",
    "        lines (list[str]): \n",
    "            list of relevant rows from `ghcnd-stations-column-metadata.txt` \n",
    "    \n",
    "    Returns:\n",
    "        (list[str]): \n",
    "            list of extracted colspecs i.e. ['1-11', '13-20', ..., '81-85']\n",
    "    \"\"\"\n",
    "    colspec_idx_start = 13\n",
    "    colspec_idx_end = 17 + 1  # Including idx 17\n",
    "    # Insert missing line\n",
    "    return colspecs\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44cd16c209eaf640a81923fb6c6ad3f1",
     "grade": true,
     "grade_id": "3333-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4c3b22be2785fd9a8e77273cb088905",
     "grade": false,
     "grade_id": "cell-6d9084804240b2d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.4:** Write a function named `get_colspec_pair` which takes as input a string variable named `colspec` and returns a tuple of integers. Specifically, the function should take a string similar to each element of `colspecs`, split this string by `-` and return a tuple of integers where\n",
    "1. The first integer should have `1` subtracted from it (Python is 0-indexed!)\n",
    "2. The second integer should stay as it is (the intervals provided to the pandas function `read_fwf` should be non-inclusive)\n",
    "> As an example, applying the function to `\"1-11\"` and `\"13-20\"` should yield the following results:\n",
    "\n",
    "```python\n",
    "print(get_colspec_pair(\"1-11\"))\n",
    "## output: (0, 11)\n",
    "\n",
    "print(get_colspec_pair(\"13-20\"))\n",
    "## output: (12, 20)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fa3780ae35b45977761ba2fb454216a",
     "grade": false,
     "grade_id": "3334",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fee8d5b0d56d0ec1a96ed593c59a0d4",
     "grade": true,
     "grade_id": "3334-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ff7f17567aa4e2fbb44af24bdbcc986",
     "grade": false,
     "grade_id": "cell-cbaa1e1dca8e3015",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.5:** Use the `get_colspec_pair` function in a list comprehension where you apply the function to each element in `colspecs`. Store the result in a variable named `colspec_pairs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3afbf83d84156e24b17573026dfa8248",
     "grade": false,
     "grade_id": "3335",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a12fae1b1b368de38f3c30a3e1cdc965",
     "grade": true,
     "grade_id": "3335-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2be26e96b4592760cfc20c18c6da9b1e",
     "grade": false,
     "grade_id": "cell-5535ad3d8666836b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.6:** Because the fixed width column information spans the interval from `13` up and including index `17`, we know that the entries from `0` to `13` (non-inclusive) are the column names and the entries from `18` to the end of each line are the data types. Write two functions named `get_column_names` and `get_column_dtypes` which return a list of column names and a list of the data types of the columns, respectively. Remember to strip all redundant whitespace using the string method `strip`. Apply the function `get_column_names` to the `lines` variable and store the output in a variable named `column_names`. Likewise, apply the function `get_column_dtypes` to the `lines` variable and store the output in a variable named `column_dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f19450632f6c6d1d4d948405258b3f5c",
     "grade": false,
     "grade_id": "3336",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a4ad3c2aaa3e244b71d02a9c0d99303",
     "grade": true,
     "grade_id": "3336-tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42c0ef12aadd154859e3b41b8c7fabc1",
     "grade": false,
     "grade_id": "cell-6a9d81f37628d1ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.7:** Replace each `\"character\"` entry with `\"str\"` and each `\"real\"` entry with `\"float32\"` of the list `column_dtypes`. Store the result of this in the same variable `column_dtypes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c43672a0ccde0a6cb5b628a91dfcd4d",
     "grade": false,
     "grade_id": "3337",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3afd09a2073e36c109317f6e1f1b56e",
     "grade": true,
     "grade_id": "3337-tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "517454579c02edf82638e4d2f6769d05",
     "grade": false,
     "grade_id": "cell-75834af9070629b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.8:** Load the `ghcnd-stations.txt` data using the `read_fwf` method of pandas setting the `names` parameter equal to `column_names` and the `colspecs` parameter equal to  `colspec_pairs`. Store the result in a variable named `locations`. Next, use the `astype` method on `locations` to set the dtypes of the columns. Use the `col_to_dtype` mapping below as input argument to `astype`. Finally, rename the `id` column to `station` and left-merge `locations` onto `df_weather_period`. Store the merged dataframe in the variable `df_weather_merged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f95d9887f5f7d1bb9294ef49c9ac05e3",
     "grade": true,
     "grade_id": "3338",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "col_to_dtype = dict(zip(column_names, column_dtypes))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9a4a76770858c976a5b06ed3ae844c1",
     "grade": false,
     "grade_id": "cell-5ba4eb25c926ef77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.9:** Subset `df_weather_period` by all weather stations in Ontario (all stations in Ontario have `state == \"ON\"`) and store the resulting DataFrame in `df_ontario`. Compute the average `obs_value` for each `station`. Store the result in a dictionary named `avg_obs_value_ontario` with the keys being the station names and the values the average `obs_value`. Finally, subset the `locations` dataframe by the querying all stations contained in the keys of `avg_obs_value_ontario`. Store the result in `locations_ontario`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "281bdf9651d8963912d805659386a298",
     "grade": false,
     "grade_id": "3339",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0c4d941c8aa454f62466c826d87602a",
     "grade": true,
     "grade_id": "3339-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c3a1d9147bc363623dcefcb7c27d5d5",
     "grade": false,
     "grade_id": "cell-8d4c53302d51c9db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.10 (OPTIONAL)**: The following exercise does not count towards the grade of this assignment. Let's try to plot the stations for Ontario on a map of Ontario. We'll use the [`folium`](http://python-visualization.github.io/folium/) package to do this. This package is not pre-installed with `anaconda`. Run the cell below to install the package or open up your terminal, activate your preferred conda environment and type `!pip install folium`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8765bee40dfff161e74121cdcf5fcb42",
     "grade": false,
     "grade_id": "cell-444d95c01e37753f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.3.3.10 (continued)**:\n",
    "> We want to plot the stations in `locations_ontario` on top of a map of Ontario. To do this, we need to create a `folium.Marker` for each station and place this on the folium map named `m` in the cell below starting with `import folium`. To accomplish this do the following:\n",
    "- Iterate through the `zipper` defined in the cell below using a list comprehension and apply the `get_marker` function at each iteration. \n",
    "    - The `zipper` object yields a tuple of 4 values in each iteration. \n",
    "- The `avg_temp` argument of `get_marker` should take the value of each given station from the `avg_obs_value_ontario` dictionary created in the previous exercise. If the loop variable corresponding to `locations_ontario.station` is named `station_id` the value can be computed by subsetting the dictionary as  `avg_obs_value_ontario[station_id]`.\n",
    "- Store the result in a variable named `markers_ontario`. The result should be a list of `folium.Markers` for each of the stations.\n",
    "\n",
    "The resulting plot should be an interactive plot similar to the one in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4cd34d87209cc1d736bf17963ca1278",
     "grade": false,
     "grade_id": "cell-09786db74bccea07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Resulting folium plot\n",
    "from IPython.display import Image\n",
    "Image(filename='ontario-example-plot.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4402f4bff9fb1f9e77ba879131dfdef4",
     "grade": true,
     "grade_id": "33310",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "\n",
    "def get_marker(lat, lon, station_name, avg_obs_value, icon='cloud', color=\"blue\"):\n",
    "    \"\"\"Creates a `folumn.Marker` for a given station\n",
    "    \n",
    "    Args:\n",
    "        (lat): lattitude of station\n",
    "        (lon): longitude of station\n",
    "        (station_name): name of station\n",
    "        (avg_obs_value): avg. obs_value for given station\n",
    "        \n",
    "    Returns:\n",
    "        (folium.Marker): object to be added to a folium map\n",
    "    \"\"\"\n",
    "    popup = \"\\n\".join([station_name, f\"Avg. obs_value: {avg_obs_value:.2f}\"])\n",
    "    marker = folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        popup=popup,\n",
    "        icon=folium.Icon(icon=icon, color=color, )\n",
    "    )\n",
    "    return marker\n",
    "\n",
    "\n",
    "# Create folium map centered on Ontario\n",
    "# COORDS_ONTARIO = (51.730703, -86.938937)\n",
    "COORDS_ONTARIO = (43.40168574192175, -80.33021323830818)\n",
    "m = folium.Map(location=COORDS_ONTARIO, zoom_start=6)\n",
    "\n",
    "# Zipper object to iterate through\n",
    "zipper = zip(\n",
    "    locations_ontario.latitude,\n",
    "    locations_ontario.longitude,\n",
    "    locations_ontario.name,\n",
    "    locations_ontario.station   \n",
    ")\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# add weather station markers to map \n",
    "for station_marker in markers_ontario:  \n",
    "    station_marker.add_to(m)\n",
    "m  # Display map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eaf086f4f6724e090ef66a74eff4517e",
     "grade": false,
     "grade_id": "cell-422d30deb292b4c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 4:\n",
    "\n",
    "> **Ex. 4.3.5 (sligthly modified):** This exercise consists of a set of small subelements: \n",
    ">\n",
    "> 0. Show the first five rows of the titanic dataset. What information is in the dataset?\n",
    "> 1. Use a barplot to show the probability of survival for men and women within each passenger class. \n",
    "> 2. Can you make a boxplot showing the same information (why/why not?). \n",
    "> 3. Show a boxplot for the fare-prices within each passenger class. \n",
    "> 4. Create a new subfolder as done in Ex. 2.X.1 this time named `figs`. Use the same approach as in Ex. 2.X.1 and store the `Path` object in a variable named `fp_figs`. \n",
    "> 5. Combine the two of the figures you created above into a two-panel figure and save it on your computer in the `figs` subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e46d24e4bd08f8870982dd932ddd15f1",
     "grade": true,
     "grade_id": "problem_435",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.3.6:** Using the iris flower dataset, draw a scatterplot of sepal length and petal length. Include a second order polynomial fitted to the data. Add a title to the plot and rename the axis labels.\n",
    ">\n",
    "> _Write 3 sentences:_ Is this a meaningful way to display the data? What could we do differently?\n",
    ">\n",
    "> For a better understanding of the dataset this image might be useful:\n",
    "\n",
    "> <img src=\"example-iris-q436.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    ">\n",
    "> _Hint:_ Use the `.regplot` method from seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e41badd527517260b61cead987a91cf",
     "grade": true,
     "grade_id": "problem_436",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4330f62f04b07d60e818eb1893bbf82d",
     "grade": false,
     "grade_id": "cell-e6d0c56f1cf535c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 4.3.7:** Use [pairplot with hue](https://seaborn.pydata.org/generated/seaborn.pairplot.html) to create a figure that clearly shows how the different species vary across measurements in the iris dataset. Change the color palette and remove the shading from the density plots. _Bonus:_ Try to explain how the `diag_kws` argument works (_hint:_ [read here](https://stackoverflow.com/questions/1769403/understanding-kwargs-in-python))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19e3feab810ee078ec29408d99334983",
     "grade": true,
     "grade_id": "problem_437",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
